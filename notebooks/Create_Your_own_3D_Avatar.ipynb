{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrogengo/3D_avatar_generator/blob/main/notebooks/Create_Your_own_3D_Avatar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "95OjyMJ2unG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ritwikraha/TripoSR.git"
      ],
      "metadata": {
        "id": "tSl0YsmPVbfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/TripoSR/tsr')"
      ],
      "metadata": {
        "id": "C1AMDudrVe0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TripoSR"
      ],
      "metadata": {
        "id": "CCNWQaOTVpa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q\n",
        "!pip install -U diffusers accelerate -qq"
      ],
      "metadata": {
        "id": "WTzcHZfZVv8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust device based on CUDA availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Zmpct28ZfJe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "MMccH9kRdXCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTqpay4mTukL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image, DDIMScheduler\n",
        "from transformers import CLIPVisionModelWithProjection\n",
        "from diffusers.utils import load_image\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import Video\n",
        "from tsr.system import TSR\n",
        "from tsr.utils import remove_background, resize_foreground, save_video\n",
        "import rembg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Pipelines for Image Preprocessing\n"
      ],
      "metadata": {
        "id": "EamN4hKMdbw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_encoder = CLIPVisionModelWithProjection.from_pretrained(\n",
        "    \"h94/IP-Adapter\",\n",
        "    subfolder=\"models/image_encoder\",\n",
        "    torch_dtype=torch.float16,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "4jZEm7RtvTYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    image_encoder=image_encoder,\n",
        ").to(device)\n",
        "pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n",
        "pipeline.load_ip_adapter(\n",
        "  \"h94/IP-Adapter\",\n",
        "  subfolder=\"sdxl_models\",\n",
        "  weight_name=[\"ip-adapter-plus_sdxl_vit-h.safetensors\", \"ip-adapter-plus-face_sdxl_vit-h.safetensors\"]\n",
        ")\n",
        "pipeline.set_ip_adapter_scale([0.7, 0.3])\n",
        "pipeline.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "y22rJI2HT9lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Timer Class for Utility"
      ],
      "metadata": {
        "id": "_LC7p8f1diBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Timer class\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self.items = {}\n",
        "        self.time_scale = 1000.0  # ms\n",
        "        self.time_unit = \"ms\"\n",
        "\n",
        "    def start(self, name: str) -> None:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        self.items[name] = time.time()\n",
        "\n",
        "    def end(self, name: str) -> float:\n",
        "        if name not in self.items:\n",
        "            return\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        start_time = self.items.pop(name)\n",
        "        delta = time.time() - start_time\n",
        "        t = delta * self.time_scale\n",
        "        print(f\"{name} finished in {t:.2f}{self.time_unit}.\")\n",
        "\n",
        "timer = Timer()"
      ],
      "metadata": {
        "id": "EmFrm9-nV2h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload your data and Generate Avatar Image"
      ],
      "metadata": {
        "id": "LkyLRcwbw5QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload your picture"
      ],
      "metadata": {
        "id": "ZHkiiXkjw9ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "CuDnCQ1QwfHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enter a prompt { run: \"auto\", vertical-output: true, form-width: \"10000px\", display-mode: \"form\" }\n",
        "prompt = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "ymHhrBsTebxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload the style images to guide the generation\n",
        "\n",
        "Here, we are using some images hosted on HF that have the funko pop style. If you want, you can change it to use any style you want."
      ],
      "metadata": {
        "id": "YTdscDFvxBtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "face_image = Image.open(list(uploaded.keys())[0])\n",
        "style_folder = \"https://huggingface.co/datasets/pedrogengo/funkopop_images/resolve/main\"\n",
        "style_images = [load_image(f\"{style_folder}/funko{i}.jpeg\").resize((1024, 1024)) for i in range(1, 5)]"
      ],
      "metadata": {
        "id": "8XXQ8v1kUDcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate images using the pipeline"
      ],
      "metadata": {
        "id": "jPEvQK7heH8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(device=device).manual_seed(42)\n",
        "\n",
        "image = pipeline(\n",
        "    prompt=prompt,\n",
        "    ip_adapter_image=[style_images, face_image],\n",
        "    negative_prompt=\"monochrome, lowres, bad anatomy, worst quality, low quality\",\n",
        "    num_inference_steps=50, num_images_per_prompt=1,\n",
        "    generator=generator,\n",
        ").images[0]"
      ],
      "metadata": {
        "id": "yEF4fivQUKLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.resize((512, 512))"
      ],
      "metadata": {
        "id": "OVmbJpvyWgfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.resize((512, 512)).save(\"examples/avatar.jpg\")"
      ],
      "metadata": {
        "id": "Mh-cM8X7XlSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The TripoSR model for 3D Avatar"
      ],
      "metadata": {
        "id": "mAl7yU3YfWzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for running the TripoSR\n",
        "image_paths = \"/content/TripoSR/examples/avatar.jpg\"\n",
        "device = \"cuda:0\"\n",
        "pretrained_model_name_or_path = \"stabilityai/TripoSR\"\n",
        "chunk_size = 8192\n",
        "no_remove_bg = True\n",
        "foreground_ratio = 0.85\n",
        "output_dir = \"output/\"\n",
        "model_save_format = \"obj\"\n",
        "render = True"
      ],
      "metadata": {
        "cellView": "code",
        "id": "EEaO83GEWNJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = output_dir.strip()\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "8Y_Cb-CifDC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Images for the 3D model"
      ],
      "metadata": {
        "id": "L3OLcSwnhrKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "timer.start(\"Initializing model\")\n",
        "model = TSR.from_pretrained(\n",
        "    pretrained_model_name_or_path,\n",
        "    config_name=\"config.yaml\",\n",
        "    weight_name=\"model.ckpt\",\n",
        ")\n",
        "model.renderer.set_chunk_size(chunk_size)\n",
        "model.to(device)\n",
        "timer.end(\"Initializing model\")\n",
        "\n",
        "# Process images\n",
        "timer.start(\"Processing images\")\n",
        "images = []\n",
        "\n",
        "\n",
        "rembg_session = rembg.new_session()\n",
        "\n",
        "image = remove_background(image, rembg_session)\n",
        "image = resize_foreground(image, foreground_ratio)\n",
        "\n",
        "if image.mode == \"RGBA\":\n",
        "  image = np.array(image).astype(np.float32) / 255.0\n",
        "  image = image[:, :, :3] * image[:, :, 3:4] + (1 - image[:, :, 3:4]) * 0.5\n",
        "  image = Image.fromarray((image * 255.0).astype(np.uint8))\n",
        "\n",
        "image_dir = os.path.join(output_dir, str(0))\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "image.save(os.path.join(image_dir, \"input.png\"))\n",
        "images.append(image)\n",
        "timer.end(\"Processing images\")"
      ],
      "metadata": {
        "id": "ndohLkwXWYME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the image\n",
        "image"
      ],
      "metadata": {
        "id": "dBb2VUaEZd_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Render Video from Images"
      ],
      "metadata": {
        "id": "HQdOgP_1hvsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each image\n",
        "for i, image in enumerate(images):\n",
        "    print(f\"Running image {i + 1}/{len(images)} ...\")\n",
        "\n",
        "    # Run model\n",
        "    timer.start(\"Running model\")\n",
        "    with torch.no_grad():\n",
        "        scene_codes = model([image], device=device)\n",
        "    timer.end(\"Running model\")\n",
        "\n",
        "    # Rendering\n",
        "    if render:\n",
        "        timer.start(\"Rendering\")\n",
        "        render_images = model.render(scene_codes, n_views=30, return_type=\"pil\")\n",
        "        for ri, render_image in enumerate(render_images[0]):\n",
        "            render_image.save(os.path.join(output_dir, str(i), f\"render_{ri:03d}.png\"))\n",
        "        save_video(\n",
        "            render_images[0], os.path.join(output_dir, str(i), \"render.mp4\"), fps=30\n",
        "        )\n",
        "        timer.end(\"Rendering\")\n",
        "\n",
        "    # Export mesh\n",
        "    timer.start(\"Exporting mesh\")\n",
        "    meshes = model.extract_mesh(scene_codes)\n",
        "    mesh_file = os.path.join(output_dir, str(i), f\"mesh.{model_save_format}\")\n",
        "    meshes[0].export(mesh_file)\n",
        "    timer.end(\"Exporting mesh\")\n",
        "\n",
        "print(\"Processing complete.\")"
      ],
      "metadata": {
        "id": "vzHqbFqdXr_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output Video"
      ],
      "metadata": {
        "id": "8iz40eD8fyvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the video\n",
        "Video('output/0/render.mp4', embed=True)"
      ],
      "metadata": {
        "id": "Mmvw8OouZ4dG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}